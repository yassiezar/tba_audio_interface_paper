Dear associate editors and reviewers,

I would first like to sincerely thank you for your honest and helpful feedback on our work. We have taken some time to go over and implement your suggestions and we believe that we can resubmit to you an improved version of the paper. 

Reviewer 1:

The reviewer made some helpful sugestions for reframing the work such that it highlights our work's usefulness to other researchers that need to know how accurate they can expect a bone-conduction audio interface to be. In particular, the suggest framing our work as a micro-navigation problem and to provide additional details on the problem we're trying to solve and provide a number of works to support our case. We have replaced some of the references with their updated or more complete versions and added others where appropriate. Furthermore, we've added additonal lines to the introduction and system description sections to better introduce the overall project and describe the problem that this work addresses. We've also made minor changes in an attemp to better frame the contribution as suggested by this reviewer. 

They also suggested to include additional details on the group of participants with visual impairments to better contextualise their results and explain the variance in their performance. We've therefore added more details on the demographics of the participants with limited vision (age range, level of vision impairment, age of vision loss, sex) and added observational arguments on what we suspect the cause of the variance may be (small sample size, relatively high age, unfamiliarity with mobile technology compared to the younger group). The references the reviewer provided are also used to support these claims. 

Finally, the reviewer rightly pointed out that a statistical difference between 2 distributions does not imply similarity. We therefore supplemented the section in question with an additional Kolmogorov-Smirnov 2-sample test to show statistical similarity between the 2 groups' performance.

Reviewer 2:

The reviewer lodged 3 main concerns regarding the paper which we will address indivdually below.

First, the reviewer noted similar concerns to R1 with the variance in performance for the group with visual impairments. We've addressed this issue in the rebuttal for R1 by adding more detailed demographic information for each group and adding observational arguments to explain the variance. We agree that this will solve the recorded performance variance, but we hope that the statistical tests we performed on the 2 groups showing both their similarity and lack of difference will somewhat alleviate the reviewers concerns of robustness. It is not a perfect solution, but we hope you find this compromise acceptable. 

Second, the reviewer has several concerns regarding how we employed Fitts's law in our analysis, specifically that it does not seem to meet the requirements of Fitts's Law and that it seems like major overkill to emply it for a simple comparrisson where we only adjust the distance to the target.

We will begin by stating that this work forms part of a larger effort to create a mobile indoor guidance system for people with visual impairments. This work forms part of an initial investigation into effective feedback media to create an interface that can autonomously adapt its own parameters to match the user's (e.g. some users might respond better to high pitches than others). 

We therefore set out to find a metric that we can use to measure performance as a function of the interface's parameters, and in this work, the parameter was the pitch gradient that we changed. This is the main reason we performed the initial characterisation experiments to find the perception limitations 

The project that this work forms a part of initially investigated ways to create an interface that can autonomously adapt its internal parameters to better match the user's perception capabilities and limitations, thereby boosting overall guidance performance. However, to do this you need a metric that can measure performance for difference settings, as well as a general idea of what the user's perception limtations are to keep the parameter changes bounded. In this work, the participant characterisation provided the frequency perception limitation in our groups, which showed that the hi setting is roughly the perception limit and close-to-optimal (therefore a good point to set the 'default' and optimise from there). This is also where Fitts's IP comes in: assuming each user as an effective target width for a given parameter setting, we can calculate their IP and conclude that an adjustment to a parameter either improved performance or worsened it. There are some issues with this process (e.g. the we will be correlated with the parameter setting), but this work was a starting point and these issues will be resolved in the future as we move towards a fully co-adaptive user interface. We note that the true purpose of the experiments were not explained in detail in the work, but it was a delibarite choice to not bog down the readers in details of work that is very much WIP. However, we did include additional context in the introduction to at least inform the reader that there is reasoning behind using Fitts's Law beyond just the additional keywords.

The reviewer also had concerns regarding whether Fitts' Law is even applicable in this case, citing the fact that the targets we used have no physical width. Furthermore, since the targets had no width, the particpants did not have access to external feedback to verify whether they actually were on target or not.  Regarding the former, the targets were coded to have a radius of ~10cm, i.e. when they were within 10cm of the target centre, the on-target tone was emitted. This gave the targets a pseudo-width, which we could use to generate an effective width, we, which was set for each participant and setting and used to generate the lines of best fit. This was not included in the text because of an oversight on our part, but has been addressed and addded in the experiment design section. Regarding the point about no feedback for being on-target: this was a deliberate design choice on our part. The aim of these experiments were to evaluate the target-finding performance of bone-conduction headphones and explicitly informing the participants with e.g. a second audio tone when they were on-target would defeat this purpose. It is likely that in an application-setting, that a second tone would imporve the user experience and improve overall performance, but this is not appropriate for these experiments. 

Reviewer 3:

The reviewer suggested a number of improvements to the figures to increase their clarity. These have been implemented in the text. They also were confused about the large number of incorrect guesses that are located in the middle sections in fig 5+6. This is an artifact from the 2-up-1-down procedure that was used. Specifically, when a participant made many correct guesses, they would move to a more difficult setting until they eventualy aren't able to make any more correct guesses. This point of failure is expected to be in the middle region (i.e. the smallest distance from the centre and smallest frequency differencec). So, when a participant started on the outer, easier edges, we expect them to make the right decisions and move to the centre, where they will eventually fail. Indeed, this is the expected behaviour. 

Finally, the reviewer questioned the choice of virtual, dimensionless targets versus physical targets, which was possible given the RGB-D camera we used. Virtual targets were used, since we have exact control over their placement and can generate a wide variaety of randomly located targets with little additional effort. Given the experiments' goal of determining the target finding performance of the 2 groups, virtual targets were sufficient. However, in an evaluation of the interface in an actual guidance setting, physical targets would make more sense. 


TODO:
Read R1 papers and include in previous work?
Strengthen problem description 
Use [millar1994understanding, pring2008psychological] to justify the variance in performance of the blind group
Add 10cm to target size
